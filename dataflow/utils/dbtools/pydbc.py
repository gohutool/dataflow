from sqlalchemy import create_engine, Engine, text, event, make_url, inspect
from sqlalchemy.pool import QueuePool
from sqlalchemy.exc import SQLAlchemyError
from dataflow.utils.log import Logger
from dataflow.utils.utils import PageResult
from dataflow.utils.utils import json_to_str, str_isEmpty, get_unique_seq
from typing import Any, Dict, Optional,Self
from cachetools import Cache
from enum import Enum
from sqlalchemy.orm import sessionmaker, scoped_session, Session
from contextlib import contextmanager
from typing import Callable
import functools

_logger = Logger('utils.dbtools.pydbc')

class PropagationBehavior(Enum):
    """‰∫ãÂä°‰º†Êí≠Ë°å‰∏∫"""
    REQUIRED = "REQUIRED"        # ÊîØÊåÅÂΩìÂâç‰∫ãÂä°ÔºåÂ¶ÇÊûú‰∏çÂ≠òÂú®ÂàôÂàõÂª∫Êñ∞‰∫ãÂä°
    REQUIRES_NEW = "REQUIRES_NEW" # ÊÄªÊòØÂàõÂª∫Êñ∞‰∫ãÂä°
    SUPPORTS = "SUPPORTS"        # ÊîØÊåÅÂΩìÂâç‰∫ãÂä°ÔºåÂ¶ÇÊûú‰∏çÂ≠òÂú®Âàô‰ª•Èùû‰∫ãÂä°ÊñπÂºèÊâßË°å
    NOT_SUPPORTED = "NOT_SUPPORTED" # ‰ª•Èùû‰∫ãÂä°ÊñπÂºèÊâßË°åÔºåÊåÇËµ∑ÂΩìÂâç‰∫ãÂä°
    MANDATORY = "MANDATORY"      # ÂøÖÈ°ªÂ≠òÂú®ÂΩìÂâç‰∫ãÂä°ÔºåÂê¶ÂàôÊäõÂá∫ÂºÇÂ∏∏
    NEVER = "NEVER"              # ÂøÖÈ°ª‰∏çÂ≠òÂú®‰∫ãÂä°ÔºåÂê¶ÂàôÊäõÂá∫ÂºÇÂ∏∏
    
class TransactionalManager:
    """SQLAlchemy ‰∫ãÂä°ÁÆ°ÁêÜÂô®"""
       
    def __init__(self, engine):
        self.engine = engine
        self.Session = scoped_session(sessionmaker(bind=self.engine))
        self._transaction_stack = []  # ‰∫ãÂä°Ê†àÔºåÁî®‰∫éÂµåÂ•ó‰∫ãÂä°
    
    def get_session(self) -> Session:
        """Ëé∑ÂèñÂΩìÂâç‰ºöËØù"""
        return self.Session()
    
    @contextmanager
    def transaction_context(self, propagation: PropagationBehavior = PropagationBehavior.REQUIRED):
        """‰∫ãÂä°‰∏ä‰∏ãÊñáÁÆ°ÁêÜÂô®"""
        session = self.get_session()
        current_transaction = session.get_transaction()
        
        try:
            # Â§ÑÁêÜ‰∫ãÂä°‰º†Êí≠Ë°å‰∏∫
            if propagation == PropagationBehavior.REQUIRED:
                if current_transaction and current_transaction.is_active:
                    # Âä†ÂÖ•Áé∞Êúâ‰∫ãÂä°
                    _logger.DEBUG("Joining existing transaction")
                    self._transaction_stack.append(False)  # Ê†áËÆ∞‰∏∫ÂµåÂ•ó‰∫ãÂä°
                    yield session
                else:
                    # ÂºÄÂêØÊñ∞‰∫ãÂä°
                    _logger.DEBUG("Starting new REQUIRED transaction")
                    self._transaction_stack.append(True)
                    with session.begin():
                        yield session
                        
            elif propagation == PropagationBehavior.REQUIRES_NEW:
                # ÊÄªÊòØÂºÄÂêØÊñ∞‰∫ãÂä°
                _logger.DEBUG("Starting REQUIRES_NEW transaction")
                self._transaction_stack.append(True)
                with session.begin():
                    yield session
                    
            elif propagation == PropagationBehavior.SUPPORTS:
                # ÊîØÊåÅÁé∞Êúâ‰∫ãÂä°ÔºåÊ≤°ÊúâÂàô‰∏çÂºÄÂêØ
                _logger.DEBUG("Using SUPPORTS transaction behavior")
                self._transaction_stack.append(False)
                yield session
                
            elif propagation == PropagationBehavior.MANDATORY:
                # ÂøÖÈ°ªÂ≠òÂú®‰∫ãÂä°
                if not current_transaction or not current_transaction.is_active:
                    raise RuntimeError("No existing transaction found for MANDATORY propagation")
                _logger.DEBUG("Using existing MANDATORY transaction")
                self._transaction_stack.append(False)
                yield session
                
            elif propagation == PropagationBehavior.NEVER:
                # ÂøÖÈ°ª‰∏çÂ≠òÂú®‰∫ãÂä°
                if current_transaction and current_transaction.is_active:
                    raise RuntimeError("Existing transaction found for NEVER propagation")
                _logger.DEBUG("Executing without transaction (NEVER)")
                self._transaction_stack.append(False)
                yield session
                
            elif propagation == PropagationBehavior.NOT_SUPPORTED:
                # ÊåÇËµ∑ÂΩìÂâç‰∫ãÂä°
                if current_transaction and current_transaction.is_active:
                    session.expunge_all()  # ÂàÜÁ¶ªÊâÄÊúâÂØπË±°
                    session.rollback()     # ÂõûÊªöÂΩìÂâç‰∫ãÂä°‰ΩÜ‰∏çÂÖ≥Èó≠‰ºöËØù
                _logger.DEBUG("Executing without transaction (NOT_SUPPORTED)")
                self._transaction_stack.append(False)
                yield session
                
        except Exception as e:
            _logger.ERROR(f"Transaction error: {e}")
            # Âè™ÊúâÊúÄÂ§ñÂ±Ç‰∫ãÂä°ÊâçËøõË°åÂõûÊªö
            if self._transaction_stack and self._transaction_stack[-1]:
                session.rollback()
            raise
        finally:
            if self._transaction_stack:
                self._transaction_stack.pop()
            # Âè™ÊúâÂú®Ê≤°ÊúâÂµåÂ•ó‰∫ãÂä°Êó∂ÊâçÁßªÈô§‰ºöËØù
            if not self._transaction_stack:
                self.Session.remove()    
    
    @staticmethod
    def transactional(
        propagation: PropagationBehavior = PropagationBehavior.REQUIRED,
        read_only: bool = False,
        rollback_for: tuple = (Exception,),
        no_rollback_for: tuple = ()
    ):
        """
        ‰∫ãÂä°Ë£ÖÈ•∞Âô®
        
        Args:
            propagation: ‰∫ãÂä°‰º†Êí≠Ë°å‰∏∫
            read_only: ÊòØÂê¶Âè™ËØª‰∫ãÂä°
            rollback_for: ÈÅáÂà∞Ëøô‰∫õÂºÇÂ∏∏Êó∂ÂõûÊªö
            no_rollback_for: ÈÅáÂà∞Ëøô‰∫õÂºÇÂ∏∏Êó∂‰∏çÂõûÊªö
        """
        def decorator(func: Callable) -> Callable:
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                # Êü•Êâæ‰∫ãÂä°ÁÆ°ÁêÜÂô®ÂÆû‰æã
                transaction_manager = TransactionalManager._find_transaction_manager(args)
                if not transaction_manager:
                    raise ValueError("Transaction manager not found in method arguments")
                
                with transaction_manager.transaction_context(propagation) as session:
                    # Â¶ÇÊûúÊñπÊ≥ïÈúÄË¶ÅsessionÂèÇÊï∞ÔºåÂàôÊ≥®ÂÖ•
                    if TransactionalManager._function_accepts_session(func):
                        kwargs['session'] = session
                    
                    try:
                        result = func(*args, **kwargs)
                        
                        # Âè™ËØª‰∫ãÂä°Ëá™Âä®ÂõûÊªö
                        if read_only and session.in_transaction():
                            session.rollback()
                            _logger.DEBUG("Read-only transaction rolled back")
                        
                        return result
                        
                    except Exception as e:
                        # Ê£ÄÊü•ÂºÇÂ∏∏Â§ÑÁêÜËßÑÂàô
                        should_rollback = TransactionalManager._should_rollback(e, rollback_for, no_rollback_for)
                        
                        if should_rollback and session.in_transaction():
                            session.rollback()
                            _logger.DEBUG(f"Transaction rolled back due to: {e}")
                        
                        raise
            
            return wrapper
        return decorator
    
    @staticmethod    
    def _should_rollback(exception: Exception, rollback_for: tuple, no_rollback_for: tuple) -> bool:
        """Âà§Êñ≠ÊòØÂê¶Â∫îËØ•ÂõûÊªö"""
        # È¶ñÂÖàÊ£ÄÊü• no_rollback_for
        for exc_type in no_rollback_for:
            if isinstance(exception, exc_type):
                return False
        
        # ÁÑ∂ÂêéÊ£ÄÊü• rollback_for
        for exc_type in rollback_for:
            if isinstance(exception, exc_type):
                return True
        
        # ÈªòËÆ§ÂõûÊªöÊâÄÊúâÂºÇÂ∏∏
        return True

    @staticmethod    
    def _function_accepts_session(func: Callable) -> bool:
        """Ê£ÄÊü•ÂáΩÊï∞ÊòØÂê¶Êé•ÂèósessionÂèÇÊï∞"""
        import inspect
        sig = inspect.signature(func)
        return 'session' in sig.parameters

    @staticmethod
    def _find_transaction_manager(args) -> Optional[Self]:
        """‰ªéÂèÇÊï∞‰∏≠Êü•Êâæ‰∫ãÂä°ÁÆ°ÁêÜÂô®"""
        for arg in args:
            if hasattr(arg, 'transaction_manager') and isinstance(arg.transaction_manager, TransactionalManager):
                return arg.transaction_manager
            if isinstance(arg, TransactionalManager):
                return arg
        return None        



def _setup_monitoring(engine:Engine):
    """ËÆæÁΩÆËøûÊé•Ê±†ÁõëÊéß"""        
    # ËøûÊé•ÂàõÂª∫ÂíåÂÖ≥Èó≠    
    @event.listens_for(engine, "connect")
    def on_connect(dbapi_conn, connection_record):
        _logger.DEBUG(f"üÜï CONNECT - Êñ∞Âª∫ËøûÊé•: {id(dbapi_conn)}")
    
    @event.listens_for(engine, "close")
    def on_close(dbapi_conn, connection_record):
        _logger.DEBUG(f"‚ùå CLOSE - ÂÖ≥Èó≠ËøûÊé•: {id(dbapi_conn)}")
    
    # ËøûÊé•ÂèñÂá∫ÂíåÊîæÂõû
    @event.listens_for(engine, "checkout")
    def on_checkout(dbapi_conn, connection_record, connection_proxy):
        _logger.DEBUG(f"üì• CHECKOUT - ÂèñÂá∫ËøûÊé•: {id(dbapi_conn)}")
    
    @event.listens_for(engine, "checkin")
    def on_checkin(dbapi_conn, connection_record):
        _logger.DEBUG(f"üì§ CHECKIN - ÊîæÂõûËøûÊé•: {id(dbapi_conn)}")
    
    # ËøûÊé•È™åËØÅÂíåÂ§±Êïà
    @event.listens_for(engine, "checkout")
    def on_checkout_validate(dbapi_conn, connection_record, connection_proxy):
        _logger.DEBUG(f"üîç VALIDATE - È™åËØÅËøûÊé•: {id(dbapi_conn)}")
    
    @event.listens_for(engine, "invalidate")
    def on_invalidate(dbapi_conn, connection_record, exception):
        _logger.DEBUG(f"üö´ INVALIDATE - ËøûÊé•Â§±Êïà: {id(dbapi_conn)}, ÈîôËØØ: {exception}")
    
    # ËøûÊé•Ê±†Ë∞ÉÊï¥
    @event.listens_for(engine, "first_connect")
    def on_first_connect(dbapi_conn, connection_record):
        _logger.DEBUG(f"üåü FIRST_CONNECT - È¶ñÊ¨°ËøûÊé•: {id(dbapi_conn)}")
    
    @event.listens_for(engine, "soft_invalidate")
    def on_soft_invalidate(dbapi_conn, connection_record, exception):
        _logger.DEBUG(f"‚ö†Ô∏è SOFT_INVALIDATE - ËΩØÂ§±Êïà: {id(dbapi_conn)}")


INNER_PLACEHOLDER = '_$inner$_'
INNER_UPDATE_PLACEHOLDER = '_update__'


class _NULLObj:
    pass

NULL = _NULLObj()    

def _is_null(obj):
    return NULL == obj


class PydbcTools:
    def __init__(self, **kwargs):
        self._table_cache = Cache(maxsize=10000000)
        self.__config__ = kwargs
        self.__url = make_url(
                self.__config__['url']
            )
        if 'username' in self.__config__:
            self.__url = self.__url.set(username=self.__config__['username'])
        if 'password' in self.__config__:
            self.__url = self.__url.set(password=self.__config__['password'])
        
        self.engine = create_engine(
            url=self.__url,
            poolclass=QueuePool,            
            pool_size=self.__config__['pool_size'] if 'pool_size' in self.__config__ else 20,      # Â∏∏È©ªËøûÊé•Êï∞
            max_overflow=self.__config__['max_overflow'] if 'max_overflow' in self.__config__ else 10 ,          # Ë∂ÖÂá∫Ê±†ÂêéÂèØÂÜçÂª∫Â§öÂ∞ëËøûÊé•
            pool_timeout=self.__config__['pool_timeout'] if 'pool_timeout' in self.__config__ else 30 ,          # Ëé∑ÂèñËøûÊé•ÊúÄÂ§ßÁ≠âÂæÖÁßíÊï∞
            pool_recycle=self.__config__['pool_recycle'] if 'pool_recycle' in self.__config__ else 3600 ,        # ËøûÊé•ÂõûÊî∂Êó∂Èó¥ÔºàÈò≤ MySQL 8h Êñ≠ÂºÄÔºâ
            pool_pre_ping=self.__config__['ping'] if 'pool_pre_ping' in self.__config__ else True ,       # ‰ΩøÁî®Ââç pingÔºåÈò≤‚ÄúËøûÊé•Â∑≤Ê≠ª‚Äù
            
            future=True            
        )
        _setup_monitoring(self.engine)        
        # _logger.INFO(f'ÂàõÂª∫Êï∞ÊçÆÂ∫ìËøûÊé•:{self.__url}')               
        if 'test' in self.__config__:
            test = self.__config__['test']
            if test.strip() != '':
                self.queryOne(test)
        _logger.INFO(f'ÂàõÂª∫Êï∞ÊçÆÂ∫ìËøûÊé•:{self.__url}ÊàêÂäü')
    
    def getConfig(self):
        return self.__config__
    
    def getEnginee(self)->Engine:
        return self.engine
    
    def getDbType(self)->str:
        return self.engine.dialect.name.lower()
    # @overload
    # def queryMany(self, sql, params:tuple):
    #     _logger.DEBUG(f"[SQL]:{sql}")
    #     _logger.DEBUG(f"[Parameter]:{params}")
    #     try:
    #         with self.engine.begin() as connection:
    #             results = connection.execute(text(sql), params).fetchall()  # ÂèÇÊï∞‰∏∫ÂÖÉÁªÑ
    #             return results                    
    #     except Exception as e:
    #         _logger.ERROR("[Exception]", e)
    #         raise e
    
    def queryMany(self, sql, params:dict=None):
        _logger.INFO(f"[SQL]:{sql}")
        _logger.INFO(f"[Parameter]:{params}")
        try:
            with self.engine.begin() as connection:
                results = connection.execute(text(sql), params).fetchall()   # ÂèÇÊï∞‰∏∫Dict    
                rtn = []
                for one in results:
                    rtn.append(one._asdict())                
                return rtn
        except Exception as e:
            _logger.ERROR("[Exception]", e)
            raise e

    def queryOne(self, sql, params:dict=None)->dict:
        _logger.DEBUG(f"[SQL]:{sql}")
        _logger.DEBUG(f"[Parameter]:{params}")
        try:
            with self.engine.begin() as connection:
                results = connection.execute(text(sql), params).fetchone()   # ÂèÇÊï∞‰∏∫Dict                    
                return results._asdict()
        except Exception as e:
            _logger.ERROR("[Exception]", e)
            raise e

    def queryCount(self, sql, params:dict=None)->int:
        result = self.queryOne(f'select count(1) cnt from ( {sql} ) a', params)  # Ëé∑ÂèñË°å
        return result['cnt']
            
    def queryPage(self, sql, params:dict=None, page=1, pagesize=10) -> PageResult:
        total = self.queryCount(sql, params)
        if pagesize <= 0:
            list = self.queryMany(sql, params)
            return PageResult(total, pagesize, 1, 1 if total>0 else 0, list)            
        else:
            if page <= 0:
                page = 1
            if total <= 0:
                return PageResult(total, pagesize, 1, (total + pagesize - 1)//pagesize, None)
            else:
                offset = (page - 1) * pagesize                
                if params is None:
                    params = {}                    
                
                params['_offset_'] = offset
                params['_pagesize_'] = pagesize
                sql_wrap = sql + ' LIMIT :_pagesize_  OFFSET :_offset_ '
                if self.getDbType() == "postgresql": # ("postgresql", "mysql", "sqlite", "clickhouse", "openGauss", "dm", "kingbase")
                    sql_wrap = sql + ' LIMIT :_pagesize_  OFFSET :_offset_ '
                elif self.getDbType() == "mysql":
                    # sql_wrap = sql + ' LIMIT :_pagesize_  OFFSET :_offset_ '
                    sql_wrap = sql + ' LIMIT :_offset_, :_pagesize_  '
                elif self.getDbType() == "oracle":
                    sql_wrap = f'SELECT * FROM (SELECT t.*, ROWNUM rn FROM ({sql}) t) WHERE rn BETWEEN :_offset_ + 1 AND :_offset_ + :_pagesize_ '
                elif self.getDbType() == "mssql":
                    sql_wrap = sql + ' OFFSET :_offset_ ROWS FETCH NEXT :_pagesize_ ROWS ONLY'
                elif self.getDbType() == "hive":
                    sql_wrap = f'SELECT * FROM (SELECT t.*, ROW_NUMBER() OVER (ORDER BY 1) AS rn FROM ({sql}) t) WHERE rn BETWEEN :_offset_ + 1 AND :_offset_ + :_pagesize_ '                                        
                    
                
                list = self.queryMany(sql_wrap, params)
                        
                return PageResult(total, pagesize, 1, (total + pagesize - 1)//pagesize, list)

    def update(self, sql, params=None, commit=True):
        _logger.DEBUG(f"[SQL]:{sql}")
        _logger.DEBUG(f"[Parameter]:{params}")
        with self.engine.begin() as connection:
            try:
                results = connection.execute(text(sql), params)
                if commit:
                    connection.commit()
                return results.rowcount
            except Exception as e:
                connection.rollback()
                _logger.ERROR("[Exception]", e)
                raise e
            
    def insert(self, sql, params=None, commit=True):
        return self.update(sql, params, commit)

    def delete(self, sql, params=None, commit=True):
        return self.update(sql, params, commit)
        
    def insertT(self, tablename:str, params:dict=None, commit=True)->int:
        if not params:
            _logger.WARN("ÊèíÂÖ•ÂØπË±°‰∏çËÉΩ‰∏∫Á©∫")
            return 0
        
        # Ëé∑ÂèñË°®ÁªìÊûÑ‰ø°ÊÅØ
        table_info = self.get_table_info(tablename)
        if not table_info:
            _logger.ERROR(f"Êó†Ê≥ïËé∑ÂèñË°® {tablename} ÁöÑÁªìÊûÑ‰ø°ÊÅØ")
            return 0        
                
        columns_info = table_info['columns']
        auto_increment_column = table_info['auto_increment_column']
        
        valided_data = {}
        
        for field_name, field_value in params.items():
            if field_name in columns_info:
                # Ë∑≥ËøáËá™Â¢û‰∏ªÈîÆÔºàÈÄöÂ∏∏Áî±Êï∞ÊçÆÂ∫ìËá™Âä®ÁîüÊàêÔºâ
                if field_name == auto_increment_column:
                    continue
                if _is_null(field_value):
                    valided_data[field_name] = None
                else:                
                    valided_data[field_name] = field_value            
        
        if not valided_data:
            _logger.ERROR("Ê≤°ÊúâÊúâÊïàÁöÑÂ≠óÊÆµÂèØ‰ª•ÊèíÂÖ•")
            return 0
        
        # ÊûÑÂª∫ÂàóÂêçÂíåÂÄº
        quoted_columns = [self._quote_identifier(col) for col in valided_data.keys()]
        columns = ', '.join(quoted_columns)
        placeholders = ', '.join([f':{col}' for col in valided_data.keys()])
        
        # ÊûÑÂª∫ SQL ËØ≠Âè•
        sql = f'INSERT INTO {tablename} ({columns}) VALUES ({placeholders})'
        _logger.DEBUG(f'SQL={sql}')
        _logger.DEBUG(f'Paramters={valided_data}')
        
        with self.engine.begin() as connection:
            try:
                results = connection.execute(text(sql), valided_data)                    
                # Ëé∑ÂèñËá™Â¢ûÈïøID
                inserted_id = None
                if auto_increment_column:
                    inserted_id = self._get_last_insert_id(connection, tablename, auto_increment_column)
                    params[auto_increment_column] = inserted_id
                
                if commit:
                    connection.commit()
                return results.rowcount
            except Exception as e:
                connection.rollback()
                _logger.ERROR("[Exception]", e)
                raise e
        
    def updateT2(self, tablename:str, obj:dict=None, where:dict=None, condiftion:str=None, commit=True):
        if not obj:
            _logger.WARN("Êõ¥Êñ∞ÂØπË±°‰∏çËÉΩ‰∏∫Á©∫")
            return 0
        
        # Ëé∑ÂèñË°®ÁªìÊûÑ‰ø°ÊÅØ
        table_info = self.get_table_info(tablename)
        if not table_info:
            _logger.ERROR(f"Êó†Ê≥ïËé∑ÂèñË°® {tablename} ÁöÑÁªìÊûÑ‰ø°ÊÅØ")
            return 0        
                
        columns_info = table_info['columns']
        
        valided_data = {}
        
        for field_name, field_value in obj.items():
            if field_name in columns_info:                
                if _is_null(field_value):
                    valided_data[field_name] = None                    
                else:                
                    valided_data[field_name] = field_value            
        
        if not valided_data:
            _logger.ERROR("Ê≤°ÊúâÊúâÊïàÁöÑÂ≠óÊÆµÂèØ‰ª•Êõ¥Êñ∞")
            return 0
        
        # ÊûÑÂª∫ÂàóÂêçÂíåÂÄº
        quoted_columns_placeholders = [f'{self._quote_identifier(col)}=:{INNER_UPDATE_PLACEHOLDER}{col}' for col in valided_data.keys()]
        columns = ', '.join(quoted_columns_placeholders)         
        
        sql_params = {}
        for field_name, field_value in valided_data.items():
            sql_params[f'{INNER_UPDATE_PLACEHOLDER}{field_name}'] = field_value
        
        sql_params.update(where)
                    
        where_sql = ''
        
        where_data = {}
        for field_name, field_value in where.items():
            if field_name in columns_info:                
                if _is_null(field_value):
                    where_data[field_name] = None                    
                else:                
                    where_data[field_name] = field_value  
        
        if where_data:
            where_columns_placeholders = [f'{self._quote_identifier(col)}=:{col}' for col in where_data.keys()]
            where_sql = ' AND '.join(where_columns_placeholders)
                
        if not str_isEmpty(where_sql):
            where_sql = ' WHERE ' + where_sql
        
        # ÊûÑÂª∫ SQL ËØ≠Âè•
        sql = f'UPDATE {tablename} SET {columns} {where_sql}'
        _logger.INFO(f'SQL={sql}')
        _logger.INFO(f'Paramters={sql_params}')
        
        with self.engine.begin() as connection:
            try:
                results = connection.execute(text(sql), sql_params)
                if commit:
                    connection.commit()
                return results.rowcount
            except Exception as e:
                connection.rollback()
                _logger.ERROR("[Exception]", e)
                raise e
    
    def updateT(self, tablename:str, obj:dict=None, condiftion:dict=None, commit=True):
        if not obj:
            _logger.WARN("Êõ¥Êñ∞ÂØπË±°‰∏çËÉΩ‰∏∫Á©∫")
            return 0
        
        # Ëé∑ÂèñË°®ÁªìÊûÑ‰ø°ÊÅØ
        table_info = self.get_table_info(tablename)
        if not table_info:
            _logger.ERROR(f"Êó†Ê≥ïËé∑ÂèñË°® {tablename} ÁöÑÁªìÊûÑ‰ø°ÊÅØ")
            return 0        
                
        columns_info = table_info['columns']
        
        valided_data = {}        
        
        for field_name, field_value in obj.items():
            if field_name in columns_info:                
                if _is_null(field_value):
                    valided_data[field_name] = None         
                    # null_data[field_name] = None          
                else:                
                    valided_data[field_name] = field_value            
        
        if not valided_data:
            _logger.ERROR("Ê≤°ÊúâÊúâÊïàÁöÑÂ≠óÊÆµÂèØ‰ª•Êõ¥Êñ∞")
            return 0
        
        # ÊûÑÂª∫ÂàóÂêçÂíåÂÄº
        quoted_columns_placeholders = [f'{self._quote_identifier(col)}=:{INNER_UPDATE_PLACEHOLDER}{col}' for col in valided_data.keys()]
        columns = ', '.join(quoted_columns_placeholders)         
        
        sql_params = {}
        for field_name, field_value in valided_data.items():
            sql_params[f'{INNER_UPDATE_PLACEHOLDER}{field_name}'] = field_value
        
        # sql_params.update(condiftion)
        
        condiftion_data = {}
        for field_name, field_value in condiftion.items():
            if field_name in columns_info:                
                if _is_null(field_value):
                    condiftion_data[field_name] = ('IS', 'NULL')
                    # null_data[field_name] = None          
                else:                
                    condiftion_data[field_name] =('=', f':{field_name}')
                    sql_params[field_name] = field_value
                    
        where_sql = ''
        
        if condiftion_data:
            where_columns_placeholders = [f'{self._quote_identifier(col)} {item[0]} {item[1]}' for col,item in condiftion_data.items()]
            where_sql = ' AND '.join(where_columns_placeholders)
        
        if not str_isEmpty(where_sql):
            where_sql = ' WHERE ' + where_sql
        
        # ÊûÑÂª∫ SQL ËØ≠Âè•
        sql = f'UPDATE {tablename} SET {columns} {where_sql}'
        _logger.INFO(f'SQL={sql}')
        _logger.INFO(f'Paramters={sql_params}')
        
        with self.engine.begin() as connection:
            try:
                results = connection.execute(text(sql), sql_params)
                if commit:
                    connection.commit()
                return results.rowcount
            except Exception as e:
                connection.rollback()
                _logger.ERROR("[Exception]", e)
                raise e
    
    def deleteT(self, tablename:str, condiftion:dict=None, commit=True):
        
        # Ëé∑ÂèñË°®ÁªìÊûÑ‰ø°ÊÅØ
        table_info = self.get_table_info(tablename)
        if not table_info:
            _logger.ERROR(f"Êó†Ê≥ïËé∑ÂèñË°® {tablename} ÁöÑÁªìÊûÑ‰ø°ÊÅØ")
            return 0        
                
        columns_info = table_info['columns']
        sql_params = {}
        condiftion_data = {}
        for field_name, field_value in condiftion.items():
            if field_name in columns_info:                
                if _is_null(field_value):
                    condiftion_data[field_name] = ('IS', 'NULL')
                    # null_data[field_name] = None          
                else:                
                    condiftion_data[field_name] =('=', f':{field_name}')
                    sql_params[field_name] = field_value
                    
        where_sql = ''
        
        if condiftion_data:
            where_columns_placeholders = [f'{self._quote_identifier(col)} {item[0]} {item[1]}' for col,item in condiftion_data.items()]
            where_sql = ' AND '.join(where_columns_placeholders)
        
        if not str_isEmpty(where_sql):
            where_sql = ' WHERE ' + where_sql
        
        # ÊûÑÂª∫ SQL ËØ≠Âè•
        sql = f'delete from {tablename} {where_sql}'
        _logger.DEBUG(f'SQL={sql}')
        _logger.DEBUG(f'Paramters={sql_params}')
        
        with self.engine.begin() as connection:
            try:
                results = connection.execute(text(sql), sql_params)
                if commit:
                    connection.commit()
                return results.rowcount
            except Exception as e:
                connection.rollback()
                _logger.ERROR("[Exception]", e)
                raise e
    
    def _get_last_insert_id(self, connection, table_name: str, 
                           auto_increment_column: str) -> Optional[Any]:
        """Ëé∑ÂèñÊúÄÂêéÊèíÂÖ•ÁöÑËá™Â¢ûÈïøID"""        
        db_type = self.getDbType()
        
        try:
            if db_type == "mysql":
                # MySQL ‰ΩøÁî® LAST_INSERT_ID()
                result = connection.execute(text("SELECT LAST_INSERT_ID()"))
                return result.scalar()
            
            elif db_type == "postgresql":
                # PostgreSQL ‰ΩøÁî® RETURNING Â≠êÂè•Êàñ currval
                # ËøôÈáåÊàë‰ª¨‰ΩøÁî® currvalÔºåÈúÄË¶ÅÁü•ÈÅìÂ∫èÂàóÂêç
                # Ê≥®ÊÑèÔºöËøôÈúÄË¶ÅÂ∫èÂàóÂêçÈÅµÂæ™ÂëΩÂêçÁ∫¶ÂÆö
                sequence_name = f"{table_name}_{auto_increment_column}_seq"
                result = connection.execute(text(f"SELECT currval('{sequence_name}')"))
                return result.scalar()
            
            elif db_type == "sqlite":
                # SQLite ‰ΩøÁî® last_insert_rowid()
                result = connection.execute(text("SELECT last_insert_rowid()"))
                return result.scalar()
            
            elif db_type == "mssql":
                # SQL Server ‰ΩøÁî® SCOPE_IDENTITY()
                result = connection.execute(text("SELECT SCOPE_IDENTITY()"))
                return result.scalar()
            
            elif db_type == "oracle":
                # Oracle ‰ΩøÁî® RETURNING Â≠êÂè•Ôºå‰ΩÜËøôÈáåÊàë‰ª¨‰ΩøÁî®Â∫èÂàóÁöÑ currval
                # Ê≥®ÊÑèÔºöËøôÈúÄË¶ÅÁü•ÈÅìÂ∫èÂàóÂêç
                sequence_name = f"SEQ_{table_name}"
                result = connection.execute(text(f"SELECT {sequence_name}.CURRVAL FROM DUAL"))
                return result.scalar()
            
            else:
                # ÂÖ∂‰ªñÊï∞ÊçÆÂ∫ìÁöÑÈÄöÁî®ÊñπÊ≥ï
                _logger.WARN(f"Êï∞ÊçÆÂ∫ì{db_type}ÁöÑËá™Â¢ûÈïøIDËé∑ÂèñÊñπÊ≥ïÊú™ÂÆûÁé∞")
                return None
                
        except Exception as e:
            _logger.WARN(f"Ëé∑ÂèñËá™Â¢ûÈïøIDÂ§±Ë¥•: {e}")
            return None
        
    def _quote_identifier(self, identifier: str) -> str:
        """Ê†πÊçÆÊï∞ÊçÆÂ∫ìÁ±ªÂûãÂºïÁî®Ê†áËØÜÁ¨¶"""
        # Â§ßÂ§öÊï∞Êï∞ÊçÆÂ∫ì‰ΩøÁî®ÂèåÂºïÂè∑Ôºå‰ΩÜÊúâ‰∫õÊï∞ÊçÆÂ∫ì‰ΩøÁî®ÂÖ∂‰ªñÁ¨¶Âè∑
        db_type = self.getDbType()
        if db_type in ['mysql', 'sqlite']:
            return f"`{identifier}`"
        elif db_type in ['mssql']:
            return f"[{identifier}]"
        else:
            return f'"{identifier}"'
     
    def _find_auto_increment_column(self, columns_info: Dict[str, Any]) -> Optional[str]:
        """Êü•ÊâæËá™Â¢ûÈïøÂ≠óÊÆµ"""
        for col_name, col_info in columns_info.items():
            if col_info.get('autoincrement', False) and col_info.get('primary_key', False):
                return col_name
        return None
    
    def get_table_info(self, table_name: str, **kwargs) -> Dict[str, Any]:
        """Ëé∑ÂèñË°®ÁöÑÂ≠óÊÆµ‰ø°ÊÅØ"""        
        cache_key = table_name
        
        if cache_key in self._table_cache:
            _logger.DEBUG(f'‰ªéCacheÈáåÊâæÂà∞{table_name}Ë°®‰ø°ÊÅØ')
            return self._table_cache[cache_key]
        
        engine = self.engine
        try:            
            # ‰ΩøÁî® SQLAlchemy ÁöÑ inspect ÂäüËÉΩËé∑ÂèñË°®ÁªìÊûÑ
            inspector = inspect(engine)
            
            arr = table_name.split('.')
            if len(arr) == 1:
                infos = inspector.get_columns(table_name)
            else:
                infos = inspector.get_columns(arr[1], arr[0])
            # Ëé∑ÂèñÂàó‰ø°ÊÅØ
            columns_info = {}
            
            
            for column in infos:
                col_name = column['name']
                columns_info[col_name] = {
                    'type': str(column['type']),
                    'nullable': column['nullable'],
                    'default': column['default'],
                    'autoincrement': column.get('autoincrement', False),
                    'primary_key': False
                }
            
            # Ëé∑Âèñ‰∏ªÈîÆ‰ø°ÊÅØ
            
            if len(arr) == 1:
                primary_keys = inspector.get_pk_constraint(table_name)
            else:
                primary_keys = inspector.get_pk_constraint(arr[1], arr[0])
                
            if primary_keys and 'constrained_columns' in primary_keys:
                for pk_col in primary_keys['constrained_columns']:
                    if pk_col in columns_info:
                        columns_info[pk_col]['primary_key'] = True
            
            table_info = {
                'columns': columns_info,
                'primary_keys': primary_keys.get('constrained_columns', []) if primary_keys else [],
                'auto_increment_column': self._find_auto_increment_column(columns_info)
            }
            
            # ÁºìÂ≠òË°®‰ø°ÊÅØ
            self._table_cache[cache_key] = table_info
            _logger.DEBUG(f'ÁºìÂ≠ò{table_name}Ë°®‰ø°ÊÅØÂà∞Cache={table_info}')
            return table_info
            
        except SQLAlchemyError as e:
            _logger.ERROR(f"Ëé∑ÂèñË°®ÁªìÊûÑÂ§±Ë¥•: {e}")
            raise e
    
    def batch(self, sql, paramsList:list[dict|tuple]=None, batchsize:int=100, commit=True):
        _logger.DEBUG(f"[SQL]:{sql}")
        _logger.DEBUG(f"[Parameters]:{paramsList}")
        results = 0
        
        if paramsList is None or len(paramsList)==0:
            return 0
        
        with self.engine.begin() as connection:
            try:
                datas = []
                for params in paramsList:                                            
                    datas.append(params)
                    if len(datas) >= batchsize:
                        count = connection.connection.cursor().executemany(sql, datas)  # ÂèÇÊï∞‰∏∫ÂÖÉÁªÑ    
                        results += count
                        _logger.DEBUG(f'ÊâπÂ§ÑÁêÜÊâßË°å{len(datas)}Êù°ËÆ∞ÂΩïÔºåÊõ¥Êñ∞Êï∞ÊçÆ{count}')                            
                        if commit :
                            # connection.commit()
                            self.commit(connection)
                            
                        datas.clear()
                if len(datas) > 0:
                    count = connection.connection.cursor().executemany(sql, datas)  # ÂèÇÊï∞‰∏∫ÂÖÉÁªÑ    
                    results += count
                    _logger.DEBUG(f'ÊâπÂ§ÑÁêÜÊâßË°å{len(datas)}Êù°ËÆ∞ÂΩïÔºåÊõ¥Êñ∞Êï∞ÊçÆ{count}')                        
                    if commit :
                        # connection.commit()
                        self.commit(connection)
                    
                return results
            except Exception as e:
                # connection.rollback()
                self.rollback(connection)
                _logger.ERROR("[Exception]", e)
                raise e


class SimpleExpression:
    class ExpressionException(Exception):
        pass
    
    def __init__(self):
        self.param_context = {}
        self.sql = ''
    def Sql(self)->str:
        return self.sql
    def Param(self)->dict:
        return self.param_context.copy()
    def _add(self, add:str, field:str, op:str, param:any)->Self:        
        if op.upper() not in ['IN', '>', '>=', '<', '<=', '<>', '=']:
            raise SimpleExpression.ExpressionException(f'‰∏çÊîØÊåÅÊìç‰ΩúÁ¨¶{op}')
        s_k = f'p_{get_unique_seq()}'
        if self.sql :
            self.sql += f' {add} {field} {op} :{s_k}'
        else:
            self.sql += f'{field} {op} :{s_k}'            
        self.param_context[s_k] = param
        return self
    def AND(self, field:str, op:str, param:any)->Self:
        return self._add('AND', field, op, param)
    def OR(self, field:str, op:str, param:any)->Self:
        return self._add('OR', field, op, param)
    def AND_ISNULL(self, field:str, nullornot:bool)->Self:
        return self._addNULL('AND', field, nullornot)
    def OR_ISNULL(self, field:str, nullornot:bool)->Self:
        return self._addNULL('OR', field, nullornot)
    def AND_BETWEEN(self, field:str, value1:any, value2:any)->Self:
        return self._addBetween('AND', field, value1, value2)
    def OR_BETWEEN(self, field:str, value1:any, value2:any)->Self:
        return self._addBetween('OR', field, value1, value2)
    def AND_IN(self, field:str, values:list[any])->Self:
        return self._addIn('AND', field, values)
    def OR_IN(self, field:str, values:list[any])->Self:
        return self._addIn('OR', field, values)
    def AND_EXPRESSION(self, field:str, sql2:Self)->Self:
        return self._addExpression('AND', sql2)
    def OR_EXPRESSION(self, field:str, sql2:Self)->Self:
        return self._addExpression('OR', field, sql2)
    def AND_SQL(self, field:str, sql2:str, param2:dict)->Self:
        return self._addSQL('AND', sql2, param2)
    def OR_SQL(self, field:str, sql2:str, param2:dict)->Self:
        return self._addSQL('OR', sql2, param2)
    def _addExpression(self, add:str,sql2:Self)->Self:
        if sql2:
            if self.sql :
                self.sql += f' {add} {sql2.sql}'
            else:
                self.sql += f' {sql2.sql}'
            self.param_context.update(sql2.param_context)
        return self    
    def _addNULL(self, add:str, field:str, nullornot:bool)->Self:                
        sql = 'IS NULL' if nullornot else 'IS NOT NULL'
        if self.sql :
            self.sql += f' {add} {field} {sql}'
        else:
            self.sql += f' {field} {sql}'        
        return self
    def _addBetween(self, add:str, field:str, value1:any, value2:any)->Self:                
        s = get_unique_seq()
        s_k_1 = f'p_{s}_s'
        s_k_2 = f'p_{s}_e'
        if self.sql :
            self.sql += f' {add} {field} BETWEEN :{s_k_1} AND :{s_k_2}'
        else:
            self.sql += f' {field} BETWEEN :{s_k_1} AND :{s_k_2}'        
        self.param_context[s_k_1]=value1
        self.param_context[s_k_2]=value2
        return self    
    def _addIn(self, add:str, field:str, values:list[any])->Self:
        if values:
            s = get_unique_seq()
            cols = [f':p_{s}_{i}' for i, v in enumerate(values)]
            [self.param_context.update({f'p_{s}_{i}': v}) for i, v in enumerate(values)]
            col = ','.join(cols)
            if self.sql :
                self.sql += f' {add} {field} IN ({col})'
            else:
                self.sql += f' {field} IN ({col})' 
        return self  
    def _addSQL(self, add:str, sql2:str, param2:dict)->Self:        
        if self.sql :
            self.sql += f' {add} {sql2}'
        else:
            self.sql += f' {sql2}'
        self.param_context.update(param2)
        return self
        
        
# @event.listens_for(engine, "checkout")
# def on_checkout(dbapi_conn, conn_record, conn_proxy):
#     print("[Ê±†] ÂèñÂá∫ËøûÊé•", conn_record)        

# Êï∞ÊçÆÂ∫ì	Êé®ËçêÈ©±Âä®	URL Ê®°ÊùøÔºàÊää u/p/host/db Êç¢ÊàêËá™Â∑±ÁöÑÔºâ	Â§áÊ≥®
# PostgreSQL	psycopg2	postgresql+psycopg2://u:p@host:5432/db?charset=utf8	ÂÆòÊñπÊúÄÂø´
# PostgreSQL	asyncpg	postgresql+asyncpg://u:p@host:5432/db	ÂºÇÊ≠•‰∏ìÁî®
# MySQL	pymysql	mysql+pymysql://u:p@host:3306/db?charset=utf8mb4	Á∫Ø Python
# MySQL	mysqlclient	mysql+mysqldb://u:p@host:3306/db?charset=utf8mb4	C Êâ©Â±ïÔºåÊõ¥Âø´
# Oracle	cx_Oracle	oracle+cx_oracle://u:p@host:1521/?service_name=XE	ÂèØÊç¢ sid=ORCL
# SQL Server	pyodbc	mssql+pyodbc://u:p@host:1433/db?driver=ODBC+Driver+17+for+SQL+Server	Windows/Linux ÈÄöÁî®
# SQLite	ÂÜÖÁΩÆ	sqlite:///./app.dbÔºàÁõ∏ÂØπÔºâÊàñ sqlite:////absolute/path.db	Êñá‰ª∂Â∫ì
# ClickHouse	clickhouse-sqlalchemy	clickhouse+http://u:p@host:8123/db	ÈªòËÆ§ HTTP ÂçèËÆÆ
# ËææÊ¢¶ DM	dmPython	dm+dmPython://u:p@host:5236/db	ÂõΩ‰∫ßÂ∫ì
# KingBase	ksycopg2	kingbase+ksycopg2://u:p@host:54321/db

if __name__ == "__main__":    
    url = make_url('postgresql+psycopg2://root:12345@host:5432/db?charset=utf8')    
    print(url)
    url = url.set(username='liuyong')
    url = url.set(password='123456')
    print(url)
    
    # print('123123'.index(INNER_PLACEHOLDER))
    
    url = 'mysql+pymysql://u:p@localhost:61306/dataflow_test?charset=utf8mb4'
    p = PydbcTools(url=url, username='stock_agent', password='1qaz2wsx', test='select 1')
    print(p)
    # print(p.queryOne('select * from sa_security_realtime_daily limit 10'))
    # print(p.queryPage('select * from sa_security_realtime_daily order by tradedate desc', None, page=1, pagesize=10))        
    # print(p.queryPage('select * from sa_security_realtime_daily where code=:code order by tradedate desc', {'code':'300492'}, page=1, pagesize=10))
    t = p.queryPage('select * from sa_security_realtime_daily where tradedate=:tradedate order by tradedate desc', {'tradedate':'2025-09-30'}, page=1, pagesize=10)
    print(json_to_str(t))
    
    print(p.get_table_info('dataflow_test.sa_security_realtime_daily'))
    
    
    sample = '''
    {"id":435177,"tradedate":"2025-09-30","code":"920819","name":"È¢ñÊ≥∞ÁîüÁâ©","price":"4.25","changepct":"-0.47","change":"-0.02","volume":"56537","turnover":"24137761.32","amp":"1.17","high":"4.3","low":"4.25","topen":"4.3","lclose":"4.27","qrr":"0.62","turnoverpct":"0.47","pe_fwd":"170.35","pb":"1.02","mc":"5209650000","fmc":"5131906875","roc":"-0.23","roc_5min":"-0.23","changepct_60day":"1.67","changepct_currentyear":"19.72","hot_rank_em":5116,"market":"SZ","createtime":"2025-09-30 09:32:17","updatetime":"2025-09-30 17:06:09","enable":1}
    '''
    from dataflow.utils.utils import str_to_json
    sample:dict = str_to_json(sample)    
    sample.pop('id',None)
    sample.pop('high',None)
    sample['low']=NULL    
    sample['tradedate']='2025-01-05'
    # rtn = p.insertT('dataflow_test.sa_security_realtime_daily', sample)
    # print(f'Result={rtn}')
    
    sample = '''
    {"price":"4.25","changepct":"-0.47","change":"-0.02","volume":"56537","turnover":"24137761.32","amp":"1.17"}
    '''
    sample:dict = str_to_json(sample)
    sample['topen']=NULL
    rtn = p.updateT2('dataflow_test.sa_security_realtime_daily', sample, {"code":"920819","tradedate":"2025-01-05"}, "code=:code and tradedate=:tradedate")
    print(f'Result={rtn}')
    
    sample1 = '''
    {"code":"920819","tradedate":"2025-01-05","price":"4.25","changepct":"-0.47","change":"-0.02","volume":"56537","turnover":"24137761.32","amp":"1.17"}
    '''
    sample1:dict = str_to_json(sample1)
    sample1['topen']=1.0
    rtn = p.updateT('dataflow_test.sa_security_realtime_daily', sample, sample1)
    print(f'Result={rtn}')
    
    sample1['topen']=NULL
    rtn = p.deleteT('dataflow_test.sa_security_realtime_daily', sample1)
    print(f'Result={rtn}')
    
    exp = SimpleExpression()
    exp = exp.AND('code','=','920819')
    exp = exp.AND('price','=',4.25)
    exp = exp.AND('code','=','920819').AND('price','=',4.25).AND_ISNULL('volume',False)
    exp = exp.AND_IN('code',['920819','920813'])
    exp = exp.AND_BETWEEN('tradedate','2025-01-05','2026-01-06')
    exp = exp.AND('tradedate','in', ['2025-01-05','2025-01-06','2025-09-30'])
    # exp = exp.AND('tradedate','in', ('2025-01-05','2025-01-06'))
    
    # rtn = p.queryMany('select * from dataflow_test.sa_security_realtime_daily where 1=1 and price = :p_1759451586491851472896 AND tradedate in :p_1759451695196584804352 limit 10', {
    #     'p_1759451695196584804352':['2025-01-05','2025-01-06','2025-09-30'],
    #     'p_1759451586491851472896':123
    # })
    # print(f'Result1111={rtn}')
    
    # print('select * from dataflow_test.sa_security_realtime_daily where 1=1 AND ' + exp.Sql())
    # print(exp.Param())
    
    rtn = p.queryMany('select * from dataflow_test.sa_security_realtime_daily where 1=1 AND ' + exp.Sql(), exp.Param())
    print(f'Result={rtn}')
    
    print(get_unique_seq())
    print(get_unique_seq())
    print(get_unique_seq())
    print(get_unique_seq())
    print(get_unique_seq())
    
    import sys
    sys.exit()
    
    
    url = 'postgresql+psycopg2://u:p@pgvector.ginghan.com:29432/aiproxy'
    p = PydbcTools(url=url, username='postgres', password='aiproxy', test='select 1')
    print(p)
    # print(p.queryOne('select * from logs limit 10'))
    # print(p.queryPage('select * from logs order by request_at desc', None, page=1, pagesize=10))        
    # print(p.queryPage('select * from logs where endpoint=:code order by request_at desc', {'code':'/v1/chat/completions'}, page=1, pagesize=10))
    t = p.queryPage('select * from logs where endpoint=:code order by request_at desc', {'code':'/v1/chat/completions'}, page=1, pagesize=10)
    print(json_to_str(t))
    
    # url = 'oracle+cx_oracle://u:p@localhost:1521/?service_name=XE'
    url = 'oracle+oracledb://u:p@localhost:60521/?service_name=ORCL'
    p = PydbcTools(url=url, username='system', password='orcl', test='select 1 from dual')
    print(p)
    # print(p.queryOne('SELECT * FROM dba_registry'))
    # print(p.queryPage('SELECT * FROM dba_registry', None, page=1, pagesize=10))        
    # print(p.queryPage("SELECT * FROM dba_registry where version like '%'||:version||'%' order by comp_id desc", {'version':'19'}, page=1, pagesize=10))
    t = p.queryPage("SELECT * FROM dba_registry where version like '%'||:version||'%' order by comp_id desc", {'version':'19'}, page=1, pagesize=10)
    print(json_to_str(t))
    
    
    
    
    